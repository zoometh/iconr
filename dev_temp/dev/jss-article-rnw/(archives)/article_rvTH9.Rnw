\documentclass[article]{jss}

%% -- LaTeX packages and custom commands ---------------------------------------

%% recommended packages
\usepackage{thumbpdf,lmodern}
\usepackage{float,tikz}
%% another package (only for this demo article)
\usepackage{framed}
%% author pakckage
\usepackage{xcolor,caption}

\graphicspath{ {./imgs/} }

%% new custom commands
\newcommand{\class}[1]{`\code{#1}'}
\newcommand{\fct}[1]{\code{#1()}}


%% -- Article metainformation (author, title, ...) -----------------------------

%% - \author{} with primary affiliation
%% - \Plainauthor{} without affiliations
%% - Separate authors by \And or \AND (in \author) or by comma (in \Plainauthor).
%% - \AND starts a new line, \And does not.
\author{Thomas Huet\\UMR 5140}
%   \And Second Author\\Plus Affiliation}
\Plainauthor{Thomas Huet}

%% - \title{} in title case
%% - \Plaintitle{} without LaTeX markup (if any)
%% - \Shorttitle{} with LaTeX markup (if any), used as running title
\title{Modelling Pre- and Protohistorical Iconographic Compositions. The \proglang{R} package \pkg{decorr}}
\Plaintitle{Modelling Pre- and Protohistorical Iconographic Compositions. The R package 'decorr'}
\Shorttitle{Modelling Pre- and Protohistorical Iconographic Compositions}

%% - \Abstract{} almost as usual
\Abstract{
%  This short article illustrates how to write a manuscript for the
%  \emph{Journal of Statistical Software} (JSS) using its {\LaTeX} style files.
%  Generally, we ask to follow JSS's style guide and FAQs precisely. Also,
%  it is recommended to keep the {\LaTeX} code as simple as possible,
%  i.e., avoid inclusion of packages/commands that are not necessary.
%  For outlining the typical structure of a JSS article some brief text snippets
%  are employed that have been inspired by \cite{Zeileis+Kleiber+Jackman:2008},
%  discussing count data regression in \proglang{R}. Editorial comments and
%  instructions are marked by vertical bars.
  By definition, Prehistorical societies are characterised by the absence of a writing system. Writing is one of the most rational semiographical system with a clear distinction between signified and signifier -- specially in alphabetic and binary writings -- and the development of the signified on a horizontal, vertical or boustrophedon axis. Prehistorical times cover more than 99\% of the human living. Even if it is being discussed, first symbolic manifestations start around 200,000 BC \citep{dErrico00}. The duration from first symbolic expressions to start of writing represents 97\% of the human living. In illiterate societies, testimonies of symbolic systems mostly come from iconography (ceramic decorations, rock-art, statuary, etc.) and signs are displayed mostlty a discontinuous figures which can have different relationships one with another. An iconographical composition can be "read" as a spatial distribution of features having intrinsic values possibily having meaningful relationships one with another depending on their pairwise spatial proximities. 

  To understand meaningful associations of signs, geometric tools, graph analysis and statistical analysis offer great tools to recognize iconographical patterns and to infer collective conventions. We present the \pkg{decorr} \proglang{R} package which ground concepts, methods and tools to analyse ancient iconographical systems.
}

%% - \Keywords{} with LaTeX markup, at least one required
%% - \Plainkeywords{} without LaTeX markup (if necessary)
%% - Should be comma-separated and in sentence case.
\Keywords{Iconography, Prehistory, Graph Theory, Graph Drawing, Spatial Analysis, \proglang{R}}
\Plainkeywords{Iconography, Prehistory, Graph Theory, Graph Drawing, Spatial Analysis, R}

%% - \Address{} of at least one author
%% - May contain multiple affiliations for each author
%%   (in extra lines, separated by \emph{and}\\).
%% - May contain multiple authors for the same affiliation
%%   (in the same first line, separated by comma).
\Address{
  Thomas Huet\\
  UMR 5140 \\
  Archeologie des Societes Mediterraneennes\\
  Universite Paul Valery\\
  route de Mende\\
  Montpellier 34199, France\\
  E-mail: \email{thomashuet7@gmail.com}\\
%  URL: \url{https://eeecon.uibk.ac.at/~zeileis/}
}

\begin{document}
\SweaveOpts{concordance=TRUE}


%% -- Introduction -------------------------------------------------------------

%% - In principle "as usual".
%% - But should typically have some discussion of both _software_ and _methods_.
%% - Use \proglang{}, \pkg{}, and \code{} markup throughout the manuscript.
%% - If such markup is in (sub)section titles, a plain text version has to be
%%   added as well.
%% - All software mentioned should be properly \cite-d.
%% - All abbreviations should be introduced.
%% - Unless the expansions of abbreviations are proper names (like "Journal
%%   of Statistical Software" above) they should be in sentence case (like
%%   "generalized linear models" below).

\section[Introduction: Count data regression in R]{Introduction: Count data regression in \proglang{R}} \label{sec:intro}

\begin{leftbar}
The introduction is in principle ``as usual''. However, it should usually embed
both the implemented \emph{methods} and the \emph{software} into the respective
relevant literature. For the latter both competing and complementary software
should be discussed (within the same software environment and beyond), bringing
out relative (dis)advantages. All software mentioned should be properly
\verb|\cite{}|d. (See also Appendix~\ref{app:bibtex} for more details on
\textsc{Bib}{\TeX}.)

For writing about software JSS requires authors to use the markup
\verb|\proglang{}| (programming languages and large programmable systems),
\verb|\pkg{}| (software packages), \verb|\code{}| (functions, commands,
arguments, etc.). If there is such markup in (sub)section titles (as above), a
plain text version has to be provided in the {\LaTeX} command as well. Below we
also illustrate how abbrevations should be introduced and citation commands can
be employed. See the {\LaTeX} code for more details.
\end{leftbar}

%Modeling count variables is a common task in economics and the social sciences.
%The classical Poisson regression model for count data is often of limited use in
%these disciplines because empirical count data sets typically exhibit
%overdispersion and/or an excess number of zeros. The former issue can be
%addressed by extending  the plain Poisson regression model in various
%directions: e.g., using sandwich covariances or estimating an additional
%dispersion parameter (in a so-called quasi-Poisson model). Another more formal
%way is to use a negative binomial (NB) regression. All of these models belong to
%the family of generalized linear models (GLMs). However, although these models
%typically can capture overdispersion rather well, they are in many applications
%not sufficient for  modeling excess zeros. Since \cite{Mullahy:1986} there is
%increased interest in zero-augmented models that address this issue by a second
%model component capturing zero counts. An overview of count data models in
%econometrics, including  hurdle and zero-inflated models, is provided in
%\cite{Cameron+Trivedi:2013}.

For decades, study of ancient iconography was linked to history of religion because closely linked to symbolism, believes and religions. Since the \textit{New Archaeology} developpement during the 60's \citep{Clarke14}, symbolic expressions start to be studied with the same formal methods (statistics, seriations, distribution maps, etc.) as any another aspect of social organisation: settlement patterns, tools \emph{chaine op√©ratoire}, susbsitence strategies, etc. \citep{Renfrew91}, \citep{LeroiGourhan92}. But unlike many aspects of the material culture -- a flint blade for cutting, a pottery for containing, a house for living --, the function of an iconographic composition cannot be drawn directly from itself. Whether study of ancient iconography had  undergone significative improvements at the site scale -- with GIS, database, paleoclimatic restitutions, etc. -- and at the sign scale with the development of archaeological sciences -- radiocarbon dating, use-wear analysis, elemental analysis, etc. --, these improvement do not necessarly help to understand the semantic content of the iconography.

Semantics or semiotics can be defined as a system of conventional and repetead signs organised also in conventional manners . As any formal system, iconography can be seen as spatial features related one with the other depending on rules of proximities. 

Until our days, formal methods to study ancient iconography Semantics, has been mostlty been grounded (explicitly or not) on the prime principle of Saussurian linguistic: the 'linearity of the signifier' \citep{Saussure89}. This principle states that the meaning of a lingusitic or writing pattern is linear and directed. Let us take the example of the word "\code{art}" which contains three vertices (\code{a}, \code{r}, \code{t}) and two edges (one between \code{a} and \code{r}, the other between \code{r} and \code{t}). 

\begin{minipage}{0.8\textwidth}
\centering
<<art_only, echo=FALSE, fig=TRUE, width=3>>=
library(igraph);library(extrafont)
# loadfonts(device = "win")
# ugs <- data.frame(name=c("a","r","t"))
# lks <- data.frame(from=c("a", "r"),to=c("r", "t"),type=c("=","="))
# g <- graph_from_data_frame(lks, directed=FALSE, vertices= ugs)
g <- graph_from_literal(a-+r, r-+t)
# lo <- cbind(seq(-1,1,length.out = gorder(g)), 0)
plot(g,
     layout = cbind(seq(-1,1,length.out = gorder(g)), 0),
     vertex.color="white",
     vertex.frame.color="white",
     vertex.size=60,
     vertex.label.cex=1.5,
     vertex.label.color="black",
     vertex.label.family="Courier New",
     edge.arrow.size=.5)
@
\captionof{figure}[unidirectiona links]{\code{a}, \code{r} and \code{t} graphical units is \code{art}.}
\end{minipage}


Applying this principle to any other graphical content than a writing, allows to considered as the organisation of graphical as a relationship of \emp{figures} grouping graphical units, \emp{patterns} grouping \emp{figures}, \emp{motives} grouping \emp{patterns}, etc., until the entire decorated support is described and can be compared to another decoration (XXX). But during this \emph{decomposition} process, the groups and relationships are often defined empirically, their level of significance are often implicit and the iconographical and spatial proximities between graphical units and categories of graphical units are not quantified. Furthermore, due to the inherent variability of iconography, most of the studies developp proper descriptive vocabularies, singular relationships of categories, idosyncratic methods in a site-dependend or period-dependend scales. This limits drastically the possibility to conduct cross-cultural comparisons and to draw a synthesis of humankind's symbolism at a large scale and over the long-term. 
\\
In this article we present the \proglang{R} package \pkg{decorr}. Its purpose is to formalise a method based on geometric graphs to analyse any graphical content. The idea is that a graphical system can be represented by vertices connected (or not) to each other with edges. This package has been grounded on the seminal work of C. Alexander \citep{Alexander08} and its first IT implementation by T. Huet \citep{Huet18a}. 

Just like in \proglang{R}, the features \code{a}, \code{r} and \code{t} concatenated in this order with a \code{paste0()}, mean "\code{art}", and not "\code{rat}". In illetrate societies, spatial relations between graphical features are not necessarly linear and directed but multi-directional and undirected: the direction of the interactions of pairwise graphical units can be in any order.  

\begin{minipage}{0.8\textwidth}
\centering
<<art_or_rat, echo=FALSE, fig=TRUE, height=3,width=3>>=
library(extrafont)
loadfonts(device = "win")
ugs <- data.frame(name=c("a","r","t"))
lks <- data.frame(from=c("a", "r", "t"),to=c("r", "t", "a"),type=c("=","=","="))
g <- graph_from_data_frame(lks, directed=FALSE, vertices= ugs)
plot(g,
     vertex.color="white",
     vertex.frame.color="white",
     vertex.size=80,
     vertex.label.cex=1.5,
     vertex.label.color="black",
     vertex.label.family="Courier New"
     )
@
\captionof{figure}[multidirectional links]{Potential spatial relations between \code{a}, \code{r} and \code{t} graphical units.}
\end{minipage}

\section[Concepts]{Concepts} \label{sec:concepts}

Graph theory offers a conceptual framework and indices (global at the entire graph scale, local at the vertex scale) to deal with notions of networks, relationships and neighbourhoods. The spatial levels of the graphical units can be retrieve by a planar graph (Graph Theory) and a spatial (GIS) analysis.

Nodes and edges -- repectively for graphical units and their connexion -- are created on a GIS interface. In the GIS, the decoration figure is open in the first place in a new project with no projection. The decoration image will be considerated as the basemap of the project and will cover the region of interest of the analysis. The decoration image can be binarized where graphical units are considerated active and the undecorated parts of the support, or background, are considerated inactive. After what, the decoration image is tiled. A simplier solution will be to create directly centroids over the graphical units. The \emph{x} and \emph{y} coordinates of the nodes are relative to the decoration and measured in pixels.
Exist a link between a couple of graphical units when these graphical units share a border. A planar graph is constructed from grahical units (nodes) and their proximity links (edges). This model is a Voronoi diagram of the support where the Voronoi seeds are the graphical units. Its geographical equivalent is a Thiessen polygon.


\begin{figure}[H]
\centering
\includegraphics{gis}
\caption{\label{fig:gis} GIS interface. A) Original decoration of the Cerro Muriano 1 steale \citep{DiazGuardamino10} with its extent (\code{xmin,xmax,ymin,ymax}); B) After the polygonisation of the graphical units, including the border of the stelae, the Voronoi cells, the centroid of graphical units and the links between graphical units having adjacent cells (ie, sharing a border) are calculated; C) For each graphical units, \emph{x} and \emph{y} are calculated; D) At least one variable, like the \code{type} of the graphical units is defined in order to compute composition analysis.}
\end{figure}

This model has a minimal of \emph{a priori} definitions. Those only concern the graphical units (type, technology, color, orientation, size, etc.). Between two graphical units the links are conventionaly represented with a plain line. But sometimes a graphical unit can be divided into a main unit (eg, a man) and attribute units (eg, a helmet, a sword). So, the links between the main unit and the attribute units are directed and displayed with a dashed line.



% \begin{center}
%  \begin{tabular}{|c c c c c c|}
%  \hline
%  graphical composition & \code{a & -- & r & -- & t} \\
%  \hline
%  \emph{centrality degrees} & \textcolor{orange}{1} & -- & \textcolor{red}{2} & -- & \textcolor{orange}{1} \\
%  \emph{betweeness degrees} & \textcolor{yellow}{0} & -- & \textcolor{red}{1} & -- & \textcolor{yellow}{0} \\
%  \hline
% \end{tabular}
% \end{center}

The \code{r} graphical unit receives two edges, so its centrality degree is 2, \code{r} is also central in the graph so its betweeness degree is 1.


%In \proglang{R} \citep{R}, GLMs are provided by the model fitting functions
%\fct{glm} in the \pkg{stats} package and \fct{glm.nb} in the \pkg{MASS} package
%\citep[][Chapter~7.4]{Venables+Ripley:2002} along with associated methods for
%diagnostics and inference. The manuscript that this document is based on
%\citep{Zeileis+Kleiber+Jackman:2008} then introduced hurdle and zero-inflated
%count models in the functions \fct{hurdle} and \fct{zeroinfl} in the \pkg{pscl}
%package \citep{Jackman:2015}. Of course, much more software could be discussed
%here, including (but not limited to) generalized additive models for count data
%as available in the \proglang{R} packages \pkg{mgcv} \cite{Wood:2006},
%\pkg{gamlss} \citep{Stasinopoulos+Rigby:2007}, or \pkg{VGAM} \citep{Yee:2009}.


%% -- Manuscript ---------------------------------------------------------------

%% - In principle "as usual" again.
%% - When using equations (e.g., {equation}, {eqnarray}, {align}, etc.
%%   avoid empty lines before and after the equation (which would signal a new
%%   paragraph.
%% - When describing longer chunks of code that are _not_ meant for execution
%%   (e.g., a function synopsis or list of arguments), the environment {Code}
%%   is recommended. Alternatively, a plain {verbatim} can also be used.
%%   (For executed code see the next section.)

\section{The R package decorr} \label{sec:models}

The \pkg{decorr} package can be downloaded from GitHub
%
\begin{CodeChunk}
\begin{CodeInput}
R>   devtools::install_github("zoometh/iconr")
\end{CodeInput}
\end{CodeChunk}
%

\subsection{External package} \label{sec:ext_pck}

The \pkg{decorr} package imports the following packages:
\begin{itemize}
  \item \pkg{magick} for image manipulation \citep{Ooms18}
  \item \pkg{igraph} for graph and network analysis \citep{Csardi06} 
  \item \pkg{rgdal}  to read shapefiles of nodes and/or edges \citep{Bivand19}
  \item \pkg{grDevices} for colors and font plotting, \pkg{graphics} for graphics, \pkg{utils} and \pkg{methods} for formally defined methods and \emph{varia} methods (all combinations, etc.) \citep{R19}
\end{itemize}


\subsection{Functions} \label{sec:functions}

The \code{list_dec()} function allows to store undirected graphs for each decorations stored into \code{nodes}, \code{edges} and \code{images} dataframes and store the graphs in a list. The join between these \emp{dataframes} is done on the two fields \code{site} and \code{decor}.\\
The \code{labels_shadow()} is a re-use of the \code{shadowtext()} function from the \pkg{TeachingDemos} package \citep{Snow20}.\\
The others \pkg{decorr} package functions can be divided into:
\begin{enumerate}
 \item functions for a single decoration
 \item functions for comparisons between different decorations
\end{enumerate}

\subsubsection{Single decoration} \label{sec:functions_one}

Functions allowing to model a single decoration with a geometric graph are:

\begin{itemize}
  \item \code{read_nds()} and \code{read_eds()} allow to read respectively a file of nodes and a file of edges (\code{.tsv} or \code{.shp} files)
  \item \code{plot_dec_grph ()} allows to plot a geometric graph over a decoration image
\end{itemize}

\subsubsection{Decoration comparisons} \label{sec:functions_one}

Functions allowing to compare different decorations with geometric graphs are:

\begin{itemize}
  \item \code{list_nds_compar()} and \code{list_eds_compar()} allow to compare respectively the common nodes and the common edges between two decorations
  \item \code{plot_nds_compar()} and \code{plot_eds_compar()} allow to plot and save two figures side-by-side for a decorations pairwise with, respectively, common nodes and common edges identified
  \item \code{same_nds()} and \code{same_eds()} allow to repectively count matching nodes and matching edges between decoration pairwises
\end{itemize}

\subsection{Function \code{listdec()}} \label{sec:funct_list_dec}

This function store graphs in a list.

\subsection{Function \code{xxx}} \label{sec:funct_etc}

xxx


The basic Poisson regression model for count data is a special case of the GLM
framework \cite{McCullagh+Nelder:1989}. It describes the dependence of a count
response variable $y_i$ ($i = 1, \dots, n$) by assuming a Poisson distribution
$y_i \sim \mathrm{Pois}(\mu_i)$. The dependence of the conditional mean
$\E[y_i \, | \, x_i] = \mu_i$ on the regressors $x_i$ is then specified via a
log link and a linear predictor
%
\begin{equation} \label{eq:mean}
\log(\mu_i) \quad = \quad x_i^\top \beta,
\end{equation}
%
where the regression coefficients $\beta$ are estimated by maximum likelihood
(ML) using the iterative weighted least squares (IWLS) algorithm.

\begin{leftbar}
Note that around the \verb|{equation}| above there should be no spaces (avoided
in the {\LaTeX} code by \verb|%| lines) so that ``normal'' spacing is used and
not a new paragraph started.
\end{leftbar}

\proglang{R} provides a very flexible implementation of the general GLM
framework in the function \fct{glm} \citep{Chambers+Hastie:1992} in the
\pkg{stats} package. Its most important arguments are
\begin{Code}
glm(formula, data, subset, na.action, weights, offset,
  family = gaussian, start = NULL, control = glm.control(...),
  model = TRUE, y = TRUE, x = FALSE, ...)
\end{Code}
where \code{formula} plus \code{data} is the now standard way of specifying
regression relationships in \proglang{R}/\proglang{S} introduced in
\cite{Chambers+Hastie:1992}. The remaining arguments in the first line
(\code{subset}, \code{na.action}, \code{weights}, and \code{offset}) are also
standard  for setting up formula-based regression models in
\proglang{R}/\proglang{S}. The arguments in the second line control aspects
specific to GLMs while the arguments in the last line specify which components
are returned in the fitted model object (of class \class{glm} which inherits
from \class{lm}). For further arguments to \fct{glm} (including alternative
specifications of starting values) see \code{?glm}. For estimating a Poisson
model \code{family = poisson} has to be specified.

\begin{leftbar}
As the synopsis above is a code listing that is not meant to be executed,
one can use either the dedicated \verb|{Code}| environment or a simple
\verb|{verbatim}| environment for this. Again, spaces before and after should be
avoided.

Finally, there might be a reference to a \verb|{table}| such as
Table~\ref{tab:overview}. Usually, these are placed at the top of the page
(\verb|[t!]|), centered (\verb|\centering|), with a caption below the table,
column headers and captions in sentence style, and if possible avoiding vertical
lines.
\end{leftbar}

\begin{table}[t!]
\centering
\begin{tabular}{lllp{7.4cm}}
\hline
Type           & Distribution & Method   & Description \\ \hline
GLM            & Poisson      & ML       & Poisson regression: classical GLM,
                                           estimated by maximum likelihood (ML) \\
               &              & Quasi    & ``Quasi-Poisson regression'':
                                           same mean function, estimated by
                                           quasi-ML (QML) or equivalently
                                           generalized estimating equations (GEE),
                                           inference adjustment via estimated
                                           dispersion parameter \\
               &              & Adjusted & ``Adjusted Poisson regression'':
                                           same mean function, estimated by
                                           QML/GEE, inference adjustment via
                                           sandwich covariances\\
               & NB           & ML       & NB regression: extended GLM,
                                           estimated by ML including additional
                                           shape parameter \\ \hline
Zero-augmented & Poisson      & ML       & Zero-inflated Poisson (ZIP),
                                           hurdle Poisson \\
               & NB           & ML       & Zero-inflated NB (ZINB),
                                           hurdle NB \\ \hline
\end{tabular}
\caption{\label{tab:overview} Overview of various count regression models. The
table is usually placed at the top of the page (\texttt{[t!]}), centered
(\texttt{centering}), has a caption below the table, column headers and captions
are in sentence style, and if possible vertical lines should be avoided.}
\end{table}


%% -- Illustrations ------------------------------------------------------------

%% - Virtually all JSS manuscripts list source code along with the generated
%%   output. The style files provide dedicated environments for this.
%% - In R, the environments {Sinput} and {Soutput} - as produced by Sweave() or
%%   or knitr using the render_sweave() hook - are used (without the need to
%%   load Sweave.sty).
%% - Equivalently, {CodeInput} and {CodeOutput} can be used.
%% - The code input should use "the usual" command prompt in the respective
%%   software system.
%% - For R code, the prompt "R> " should be used with "+  " as the
%%   continuation prompt.
%% - Comments within the code chunks should be avoided - these should be made
%%   within the regular LaTeX text.

\section{Illustrations} \label{sec:illustrations}

For a simple illustration of basic Poisson and NB count regression the
\code{quine} data from the \pkg{MASS} package is used. This provides the number
of \code{Days} that children were absent from school in Australia in a
particular year, along with several covariates that can be employed as regressors.
The data can be loaded by
%
\begin{CodeChunk}
\begin{CodeInput}
R> data("quine", package = "MASS")
\end{CodeInput}
\end{CodeChunk}
%
and a basic frequency distribution of the response variable is displayed in
Figure~\ref{fig:quine}.

\begin{leftbar}
For code input and output, the style files provide dedicated environments.
Either the ``agnostic'' \verb|{CodeInput}| and \verb|{CodeOutput}| can be used
or, equivalently, the environments \verb|{Sinput}| and \verb|{Soutput}| as
produced by \fct{Sweave} or \pkg{knitr} when using the \code{render_sweave()}
hook. Please make sure that all code is properly spaced, e.g., using
\code{y = a + b * x} and \emph{not} \code{y=a+b*x}. Moreover, code input should
use ``the usual'' command prompt in the respective software system. For
\proglang{R} code, the prompt \code{"R> "} should be used with \code{"+  "} as
the continuation prompt. Generally, comments within the code chunks should be
avoided -- and made in the regular {\LaTeX} text instead. Finally, empty lines
before and after code input/output should be avoided (see above).
\end{leftbar}

\begin{figure}[t!]
\centering
\includegraphics{article-visualization}
\caption{\label{fig:quine} Frequency distribution for number of days absent
from school.}
\end{figure}

As a first model for the \code{quine} data, we fit the basic Poisson regression
model. (Note that JSS prefers when the second line of code is indented by two
spaces.)
%
\begin{CodeChunk}
\begin{CodeInput}
R> m_pois <- glm(Days ~ (Eth + Sex + Age + Lrn)^2, data = quine,
+    family = poisson)
\end{CodeInput}
\end{CodeChunk}
%
To account for potential overdispersion we also consider a negative binomial
GLM.
%
\begin{CodeChunk}
\begin{CodeInput}
R> library("MASS")
R> m_nbin <- glm.nb(Days ~ (Eth + Sex + Age + Lrn)^2, data = quine)
\end{CodeInput}
\end{CodeChunk}
%
In a comparison with the BIC the latter model is clearly preferred.
%
\begin{CodeChunk}
\begin{CodeInput}
R> BIC(m_pois, m_nbin)
\end{CodeInput}
\begin{CodeOutput}
       df      BIC
m_pois 18 2046.851
m_nbin 19 1157.235
\end{CodeOutput}
\end{CodeChunk}
%
Hence, the full summary of that model is shown below.
%
\begin{CodeChunk}
\begin{CodeInput}
R> summary(m_nbin)
\end{CodeInput}
\begin{CodeOutput}
Call:
glm.nb(formula = Days ~ (Eth + Sex + Age + Lrn)^2, data = quine,
    init.theta = 1.60364105, link = log)

Deviance Residuals:
    Min       1Q   Median       3Q      Max
-3.0857  -0.8306  -0.2620   0.4282   2.0898

Coefficients: (1 not defined because of singularities)
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  3.00155    0.33709   8.904  < 2e-16 ***
EthN        -0.24591    0.39135  -0.628  0.52977
SexM        -0.77181    0.38021  -2.030  0.04236 *
AgeF1       -0.02546    0.41615  -0.061  0.95121
AgeF2       -0.54884    0.54393  -1.009  0.31296
AgeF3       -0.25735    0.40558  -0.635  0.52574
LrnSL        0.38919    0.48421   0.804  0.42153
EthN:SexM    0.36240    0.29430   1.231  0.21818
EthN:AgeF1  -0.70000    0.43646  -1.604  0.10876
EthN:AgeF2  -1.23283    0.42962  -2.870  0.00411 **
EthN:AgeF3   0.04721    0.44883   0.105  0.91622
EthN:LrnSL   0.06847    0.34040   0.201  0.84059
SexM:AgeF1   0.02257    0.47360   0.048  0.96198
SexM:AgeF2   1.55330    0.51325   3.026  0.00247 **
SexM:AgeF3   1.25227    0.45539   2.750  0.00596 **
SexM:LrnSL   0.07187    0.40805   0.176  0.86019
AgeF1:LrnSL -0.43101    0.47948  -0.899  0.36870
AgeF2:LrnSL  0.52074    0.48567   1.072  0.28363
AgeF3:LrnSL       NA         NA      NA       NA
---
Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1

(Dispersion parameter for Negative Binomial(1.6036) family taken to be 1)

    Null deviance: 235.23  on 145  degrees of freedom
Residual deviance: 167.53  on 128  degrees of freedom
AIC: 1100.5

Number of Fisher Scoring iterations: 1


              Theta:  1.604
          Std. Err.:  0.214

 2 x log-likelihood:  -1062.546
\end{CodeOutput}
\end{CodeChunk}



%% -- Summary/conclusions/discussion -------------------------------------------

\section{Summary and discussion} \label{sec:summary}

\begin{leftbar}
As usual \dots
\end{leftbar}




%% -- Optional special unnumbered sections -------------------------------------

\section*{Computational details}

\begin{leftbar}
If necessary or useful, information about certain computational details
such as version numbers, operating systems, or compilers could be included
in an unnumbered section. Also, auxiliary packages (say, for visualizations,
maps, tables, \dots) that are not cited in the main text can be credited here.
\end{leftbar}

The results in this paper were obtained using
\proglang{R}~3.4.1 with the
\pkg{MASS}~7.3.47 package. \proglang{R} itself
and all packages used are available from the Comprehensive
\proglang{R} Archive Network (CRAN) at
\url{https://CRAN.R-project.org/}.


\section*{Acknowledgments}

\begin{leftbar}
All acknowledgments (note the AE spelling) should be collected in this
unnumbered section before the references. It may contain the usual information
about funding and feedback from colleagues/reviewers/etc. Furthermore,
information such as relative contributions of the authors may be added here
(if any).
\end{leftbar}


%% -- Bibliography -------------------------------------------------------------
%% - References need to be provided in a .bib BibTeX database.
%% - All references should be made with \cite, \citet, \citep, \citealp etc.
%%   (and never hard-coded). See the FAQ for details.
%% - JSS-specific markup (\proglang, \pkg, \code) should be used in the .bib.
%% - Titles in the .bib should be in title case.
%% - DOIs should be included where available.

\bibliography{D:/DocumentationArcheo/biblio10}


%% -- Appendix (if any) --------------------------------------------------------
%% - After the bibliography with page break.
%% - With proper section titles and _not_ just "Appendix".

\newpage

\begin{appendix}

\section{More technical details} \label{app:technical}

\begin{leftbar}
Appendices can be included after the bibliography (with a page break). Each
section within the appendix should have a proper section title (rather than
just \emph{Appendix}).

For more technical style details, please check out JSS's style FAQ at
\url{https://www.jstatsoft.org/pages/view/style#frequently-asked-questions}
which includes the following topics:
\begin{itemize}
  \item Title vs.\ sentence case.
  \item Graphics formatting.
  \item Naming conventions.
  \item Turning JSS manuscripts into \proglang{R} package vignettes.
  \item Trouble shooting.
  \item Many other potentially helpful details\dots
\end{itemize}
\end{leftbar}


\section[Using BibTeX]{Using \textsc{Bib}{\TeX}} \label{app:bibtex}

\begin{leftbar}
References need to be provided in a \textsc{Bib}{\TeX} file (\code{.bib}). All
references should be made with \verb|\cite|, \verb|\citet|, \verb|\citep|,
\verb|\citealp| etc.\ (and never hard-coded). This commands yield different
formats of author-year citations and allow to include additional details (e.g.,
pages, chapters, \dots) in brackets. In case you are not familiar with these
commands see the JSS style FAQ for details.

Cleaning up \textsc{Bib}{\TeX} files is a somewhat tedious task -- especially
when acquiring the entries automatically from mixed online sources. However,
it is important that informations are complete and presented in a consistent
style to avoid confusions. JSS requires the following format.
\begin{itemize}
  \item JSS-specific markup (\verb|\proglang|, \verb|\pkg|, \verb|\code|) should
    be used in the references.
  \item Titles should be in title case.
  \item Journal titles should not be abbreviated and in title case.
  \item DOIs should be included where available.
  \item Software should be properly cited as well. For \proglang{R} packages
    \code{citation("pkgname")} typically provides a good starting point.
\end{itemize}
\end{leftbar}

\end{appendix}

%% -----------------------------------------------------------------------------


\end{document}
