data <- data[rowSums(is.na(data)) != ncol(data), ]
if(verb){print(paste0(" - nb of rows: ", nrow(data)))}
data[is.na(data)] <- "" # rm NA value for logical tests
# BU template for BU structure only
bu <- openxlsx::read.xlsx(bu.template.path, startRow = 3)
bu <- bu[0, ]
for(i in seq(1, nrow(data))){
bu[nrow(bu) + 1, ] <- NA
}
#
#     # BU structure only
#     mapping.file.header <- na.omit(mapping.file[ , eamena.field])
#     bu <- data.frame(matrix(ncol = length(mapping.file.header),
#                             nrow = 0))
#     colnames(bu) <- mapping.file.header
#     for(i in seq(1, nrow(data))){
#       bu[nrow(bu) + 1, ] <- NA
#     }
# - - - - - - - - - - - - - -
# loops
# 'field'
if('field' %in% unique(mapping.file$v3_type)){
if(verb){print(paste0("     works on 'field' field type"))}
mapping.file.fields <- mapping.file[mapping.file[ , job.type] == "field", ]
# mapping.file.fields <- mapping.file.fields[!is.na(mapping.file[ , job.type]), ]
for(i in seq(1, nrow(mapping.file.fields))){
ea <- as.character(mapping.file.fields[i, eamena.field])
if(verb){print(paste0("           ... and read '", ea,"'"))}
x <- as.character(mapping.file.fields[i, job])
if(verb){if(!x %in% colnames(data)){stop(paste0("The field name '", x,"' is not present in the file '", bu.name, "'"))}}
bu[ , ea] <- data[ , x]
}
}
# 'value'
if('value' %in% unique(mapping.file$v3_type)){
if(verb){print(paste0("     works on 'value' field type"))}
mapping.file.value <- mapping.file[mapping.file[ , job.type] == "value", ]
for(i in seq(1, nrow(mapping.file.value))){
ea <- as.character(mapping.file.value[i, eamena.field])
if(verb){print(paste0("           ... and read '", ea,"'"))}
x <- as.character(mapping.file.value[i, job])
bu[ , ea] <- x
}
}
# 'expression'
if('expression' %in% unique(mapping.file$v3_type)){
if(verb){print(paste0("     works on 'expression' field type"))}
mapping.file.expres <- mapping.file[mapping.file[ , job.type] == "expression", ]
for(i in seq(1, nrow(mapping.file.expres))){
ea <- as.character(mapping.file.expres[i, eamena.field])
if(verb){print(paste0("           ... and read '", ea,"'"))}
x.text <- as.character(mapping.file.expres[i, job])
x.text <- gsub("[\r\n]", "\n", x.text)
eval(parse(text = x.text)) # the XLSX cell text is executed
}
}
# # 'value'
# if(verb){print(paste0("     works on 'value' field type"))}
# mapping.file.value <- mapping.file[mapping.file[ , job.type] == "value", ]
# for(i in seq(1, nrow(mapping.file.value))){
#   ea <- as.character(mapping.file.value[i, eamena.field])
#   if(verb){print(paste0("           ... and read '", ea,"'"))}
#   x <- as.character(mapping.file.value[i, job])
#   bu[ , ea] <- x
# }
# 'other' column
if('other' %in% unique(mapping.file$v3_type)){
if(verb){print(paste0("     works on 'other' field values"))}
mapping.file.other <- mapping.file[mapping.file[ , job.type] == "other", ]
for(i in seq(1, nrow(mapping.file.other))){
x.text <- as.character(mapping.file.other[i, job])
x.text <- gsub("[\r\n]", "\n", x.text)
eval(parse(text = x.text)) # the XLSX cell text is executed
}
}
# delete surnumerary rows
bu <- bu[!is.na(bu[ , eamena.id]), ]
bu <- bu[order(bu[ , eamena.id]),]
row.names(bu) <- seq(1, nrow(bu))
out.bu <- paste0(dirOut, DescTools::SplitPath(bu.name)$filename)
out.bu.xlsx <- paste0(out.bu, "_out.xlsx")
openxlsx::write.xlsx(bu, out.bu.xlsx, row.names = F, showNA = FALSE)
if(verb){print(paste0(" - '", bu.name, "' exported to: ",
DescTools::SplitPath(out.bu.xlsx)$drive,
DescTools::SplitPath(out.bu.xlsx)$dirname))
print("")
}
}
}
list_mapping_bu(bu.path = "C:/Rprojects/eamena-arches-dev/data/bulk/bu/v3/",
job = "v3",
job.type = "v3_type",
verb = T,
mapping.file = 'https://docs.google.com/spreadsheets/d/1nXgz98mGOySgc0Q2zIeT1RvHGNl4WRq1Fp9m5qB8g8k/edit#gid=1083097625',
mapping.file.ggsheet = T)
mapping.file.fields
mapping.file.fields[!is.na(mapping.file[ , job.type]), ]
job.type
!is.na(mapping.file[ , job.type])
mapping.file.fields[!is.na(mapping.file.fields[ , job.type]), ]
#' Fill an empty BU template with data from an unformatted XLSX
#' @name list_mapping_bu
#' @description Use a mapping file to recast the values of a source file into a format adapted to the bulk upload process (BU)
#' @param bu.path the path to the BU folder. The BU folder (`bu/`) is the root of job folders (ex: 'mk/', see the 'job' option). The output subfolder `out/` will be created by the function to store the output files. BU files could be either XLSX or CSV.
#' @param bu.template.path the path to the BU template.
#' @param mapping.file the path to the XLSX or Google Sheet file providing the equivalences (mapping) between the source file (unformatted) and the target file (formatted as a BU).
#' @param mapping.file.ggsheet is the mapping file a Google Sheet (for example: 'https://docs.google.com/spreadsheets/d/1nXgz98mGOySgc0Q2zIeT1RvHGNl4WRq1Fp9m5qB8g8k/edit#gid=1083097625'), by default: FALSE.
#' @param job the job folder is a subfolder of `bu/`. It contains the unformatted XLSX datasets. `job` is also the name of the source fields in the mapping file. By default 'mk'.
#' @param job.type the name of the field in the `mapping.file` XLSX giving the name of the mapping function to do:
#'   - 'field': one-to-one correspondences, the source values will be copied as it into the target file;
#'   - 'value': constant values (ie, always the same value) that will be copied into the target file;
#'   - 'expression': logical functions (mainly if statements). These functions are written directly in the appropriate cell of the mapping file;
#'   - 'escape': values depending from another column evaluated by 'expression'. This field is
#'       not read;
#' @param eamena.field the name of the field in the `mapping.file` XLSX with the name of the EAMENA fields in a R format ('UNIQUEID', 'Assessment.Investigator.-.Actor', 'Investigator.Role.Type', etc.)
#' @param eamena.id the unique key identifier for a single resource, by default 'UNIQUEID'
#' @param verb if TRUE (by default): verbose
#'
#' @return One or various XLSX files (almost) ready for an bulk upload process in the EAMENA DB. These files are names in the same way as the input file, except a `_out` suffix is added.
#'
#' @examples
#'
#' list_mapping_bu()
#'
#' list_mapping_bu(mapping.file = 'https://docs.google.com/spreadsheets/d/1nXgz98mGOySgc0Q2zIeT1RvHGNl4WRq1Fp9m5qB8g8k/edit#gid=1083097625',
#'                 mapping.file.ggsheet = T)
#'
#'
#' @export
list_mapping_bu <- function(bu.path = paste0(system.file(package = "eamenaR"), "/extdata/bu/"),
bu.template.path = "C:/Rprojects/eamena-arches-dev/data/bulk/templates/Heritage Place BUS Template.xlsx",
mapping.file = paste0(system.file(package = "eamenaR"), "/extdata/mapping_bu.xlsx"),
mapping.file.ggsheet = F,
job = "mk",
job.type = "mk_type",
eamena.field = "EAMENA",
eamena.id = "UNIQUEID",
verb = T){
dirOut <- paste0(bu.path, "out/")
dir.create(dirOut, showWarnings = FALSE)
# data source
data.path.folder <- paste0(bu.path)
l.bus <- setdiff(list.files(data.path.folder),
list.dirs(data.path.folder,
recursive = FALSE, full.names = FALSE))
# mapping file
if(mapping.file.ggsheet){
mapping.file <- googlesheets4::read_sheet(mapping.file)
} else {
mapping.file <-  openxlsx::read.xlsx(mapping.file)
}
cpt <- 0
for(bu.name in l.bus){
# bu.name <- "EAMENA_2022-09-26_03-23-29_test.csv"
cpt <- cpt + 1
if(verb){print(paste0(cpt, "- read: ", bu.name))}
data.path <- paste0(bu.path, bu.name)
f.extension <- DescTools::SplitPath(data.path)$extension
if(f.extension == "xlsx"){
data <- xlsx::read.xlsx(data.path,
sheetIndex = 1)
}
if(f.extension == "csv"){
data <- read.csv(data.path, encoding  = "UTF-8")
# head(data$NAME.E41)
}
data <- data[rowSums(is.na(data)) != ncol(data), ]
if(verb){print(paste0(" - nb of rows: ", nrow(data)))}
data[is.na(data)] <- "" # rm NA value for logical tests
# BU template for BU structure only
bu <- openxlsx::read.xlsx(bu.template.path, startRow = 3)
bu <- bu[0, ]
for(i in seq(1, nrow(data))){
bu[nrow(bu) + 1, ] <- NA
}
#
#     # BU structure only
#     mapping.file.header <- na.omit(mapping.file[ , eamena.field])
#     bu <- data.frame(matrix(ncol = length(mapping.file.header),
#                             nrow = 0))
#     colnames(bu) <- mapping.file.header
#     for(i in seq(1, nrow(data))){
#       bu[nrow(bu) + 1, ] <- NA
#     }
# - - - - - - - - - - - - - -
# loops
# 'field'
if('field' %in% unique(mapping.file$v3_type)){
if(verb){print(paste0("     works on 'field' field type"))}
mapping.file.fields <- mapping.file[mapping.file[ , job.type] == "field", ]
mapping.file.fields <- mapping.file.fields[!is.na(mapping.file.fields[ , job.type]), ]
for(i in seq(1, nrow(mapping.file.fields))){
ea <- as.character(mapping.file.fields[i, eamena.field])
if(verb){print(paste0("           ... and read '", ea,"'"))}
x <- as.character(mapping.file.fields[i, job])
if(verb){if(!x %in% colnames(data)){stop(paste0("The field name '", x,"' is not present in the file '", bu.name, "'"))}}
bu[ , ea] <- data[ , x]
}
}
# 'value'
if('value' %in% unique(mapping.file$v3_type)){
if(verb){print(paste0("     works on 'value' field type"))}
mapping.file.value <- mapping.file[mapping.file[ , job.type] == "value", ]
mapping.file.value <- mapping.file.value[!is.na(mapping.file.value[ , job.type]), ]
for(i in seq(1, nrow(mapping.file.value))){
ea <- as.character(mapping.file.value[i, eamena.field])
if(verb){print(paste0("           ... and read '", ea,"'"))}
x <- as.character(mapping.file.value[i, job])
bu[ , ea] <- x
}
}
# 'expression'
if('expression' %in% unique(mapping.file$v3_type)){
if(verb){print(paste0("     works on 'expression' field type"))}
mapping.file.expres <- mapping.file[mapping.file[ , job.type] == "expression", ]
mapping.file.expres <- mapping.file.expres[!is.na(mapping.file.expres[ , job.type]), ]
for(i in seq(1, nrow(mapping.file.expres))){
ea <- as.character(mapping.file.expres[i, eamena.field])
if(verb){print(paste0("           ... and read '", ea,"'"))}
x.text <- as.character(mapping.file.expres[i, job])
x.text <- gsub("[\r\n]", "\n", x.text)
eval(parse(text = x.text)) # the XLSX cell text is executed
}
}
# # 'value'
# if(verb){print(paste0("     works on 'value' field type"))}
# mapping.file.value <- mapping.file[mapping.file[ , job.type] == "value", ]
# for(i in seq(1, nrow(mapping.file.value))){
#   ea <- as.character(mapping.file.value[i, eamena.field])
#   if(verb){print(paste0("           ... and read '", ea,"'"))}
#   x <- as.character(mapping.file.value[i, job])
#   bu[ , ea] <- x
# }
# 'other' column
if('other' %in% unique(mapping.file$v3_type)){
if(verb){print(paste0("     works on 'other' field values"))}
mapping.file.other <- mapping.file[mapping.file[ , job.type] == "other", ]
for(i in seq(1, nrow(mapping.file.other))){
x.text <- as.character(mapping.file.other[i, job])
x.text <- gsub("[\r\n]", "\n", x.text)
eval(parse(text = x.text)) # the XLSX cell text is executed
}
}
# delete surnumerary rows
bu <- bu[!is.na(bu[ , eamena.id]), ]
bu <- bu[order(bu[ , eamena.id]),]
row.names(bu) <- seq(1, nrow(bu))
out.bu <- paste0(dirOut, DescTools::SplitPath(bu.name)$filename)
out.bu.xlsx <- paste0(out.bu, "_out.xlsx")
openxlsx::write.xlsx(bu, out.bu.xlsx, row.names = F, showNA = FALSE)
if(verb){print(paste0(" - '", bu.name, "' exported to: ",
DescTools::SplitPath(out.bu.xlsx)$drive,
DescTools::SplitPath(out.bu.xlsx)$dirname))
print("")
}
}
}
list_mapping_bu(bu.path = "C:/Rprojects/eamena-arches-dev/data/bulk/bu/v3/",
job = "v3",
job.type = "v3_type",
verb = T,
mapping.file = 'https://docs.google.com/spreadsheets/d/1nXgz98mGOySgc0Q2zIeT1RvHGNl4WRq1Fp9m5qB8g8k/edit#gid=1083097625',
mapping.file.ggsheet = T)
a <- "2019-11-03T00:00:00"
date(a)
as.Date(a)
class(as.Date(a))
as.character(as.Date(a))
list_mapping_bu(bu.path = "C:/Rprojects/eamena-arches-dev/data/bulk/bu/v3/",
job = "v3",
job.type = "v3_type",
verb = T,
mapping.file = 'https://docs.google.com/spreadsheets/d/1nXgz98mGOySgc0Q2zIeT1RvHGNl4WRq1Fp9m5qB8g8k/edit#gid=1083097625',
mapping.file.ggsheet = T)
cpt <- cpt + 1
if(verb){print(paste0(cpt, "- read: ", bu.name))}
data.path <- paste0(bu.path, bu.name)
f.extension <- DescTools::SplitPath(data.path)$extension
if(f.extension == "xlsx"){
data <- xlsx::read.xlsx(data.path,
sheetIndex = 1)
}
if(f.extension == "csv"){
data <- read.csv(data.path, encoding  = "UTF-8")
# head(data$NAME.E41)
}
data <- data[rowSums(is.na(data)) != ncol(data), ]
if(verb){print(paste0(" - nb of rows: ", nrow(data)))}
data[is.na(data)] <- "" # rm NA value for logical tests
seq(1, nrow(data)
)
i <- 1
data[j, "GEOMETRIC_PLACE_EXPRESSION.SP5"]
j <- 1
data[j, "GEOMETRIC_PLACE_EXPRESSION.SP5"]
geom <- data[j, "GEOMETRIC_PLACE_EXPRESSION.SP5"]
geom <- gsub("u\'","\'", geom)
geom <- gsub("\'","\"", geom)
geom.wkt <- geojsonsf::geojson_wkt(geom)
as.character(geom.wkt$geometry)
verb
for(j in seq(1, nrow(data))){
j <- 1
if(verb){print(paste0("        ... reading line ", j))}
geom <- data[j, "GEOMETRIC_PLACE_EXPRESSION.SP5"]
geom <- gsub("u\'","\'", geom)
geom <- gsub("\'","\"", geom)
geom.wkt <- geojsonsf::geojson_wkt(geom)
as.character(geom.wkt$geometry)
# bu[j, "Geometric.Place.Expression"] <- as.character(geom.wkt$geometry)
}
for(j in seq(1, nrow(data))){
#j <- 1
if(verb){print(paste0("        ... reading line ", j))}
geom <- data[j, "GEOMETRIC_PLACE_EXPRESSION.SP5"]
geom <- gsub("u\'","\'", geom)
geom <- gsub("\'","\"", geom)
geom.wkt <- geojsonsf::geojson_wkt(geom)
as.character(geom.wkt$geometry)
# bu[j, "Geometric.Place.Expression"] <- as.character(geom.wkt$geometry)
}
geojsonsf::geojson_wkt(geom)
class(try(geojsonsf::geojson_wkt(geom)))
class(try(geojsonsf::geojson_wkt(geom), silent = T)) == 'try-error'
list_mapping_bu(bu.path = "C:/Rprojects/eamena-arches-dev/data/bulk/bu/v3/",
job = "v3",
job.type = "v3_type",
verb = T,
mapping.file = 'https://docs.google.com/spreadsheets/d/1nXgz98mGOySgc0Q2zIeT1RvHGNl4WRq1Fp9m5qB8g8k/edit#gid=1083097625',
mapping.file.ggsheet = T)
remove.packages("eamenaR", lib="~/R/win-library/4.1")
devtools::install_github("eamena-oxford/eamenaR")
devtools::install_github("zoometh/iconr", build_vignettes=TRUE)
devtools::install_github("zoometh/iconr")
getwd()
setwd("C:/Rprojects/iconr")
devtools::install_github("joeroe/stratigraphr")
library(stratigraphr)
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(kableExtra)
library(dplyr)
library(igraph)
library(iconr)
# library(ggdag)
library(tidygraph)
library(ggraph)
library(png)
library(grid)
library(gridExtra)
library(stratigraphr)
ibahernando.path <- "../doc/img/ibahernando_256colours.png"
brozas.path <- "../doc/img/brozas_256colours.png"
dummies.path <- "../doc/img/dummies.png"
ibahernando <-  rasterGrob(as.raster(readPNG(ibahernando.path)), interpolate = FALSE)
oldpar <- par(no.readonly = TRUE)
on.exit(par(oldpar))
par(mar=c(0, 0, 0, 0))
g <- graph_from_literal(objects-+weapons,
objects-+personnal_item,
weapons-+offensive_weapons,
weapons-+defensive_weapons,
offensive_weapons-+spear,
offensive_weapons-+sword,
defensive_weapons-+shield,
defensive_weapons-+helmet,
personnal_item-+miror,
personnal_item-+comb)
layout <- layout.reingold.tilford(g)
plot(g,
layout = layout,
vertex.color = "white",
vertex.frame.color = "white",
vertex.size = 20,
vertex.label.cex = 0.7,
vertex.label.color = "black",
vertex.label.family = "sans",
edge.arrow.size = 0.5
)
# library(data.tree)
#
# imgs <- read.table(system.file("extdata", "imgs.csv", package = "iconr"),
#                    sep=";", stringsAsFactors = FALSE)
# nodes <- read.table(system.file("extdata", "nodes.csv", package = "iconr"),
#                     sep=";", stringsAsFactors = FALSE)
# edges <- read.table(system.file("extdata", "edges.csv", package = "iconr"),
#                     sep=";", stringsAsFactors = FALSE)
# lgrph <- list_dec(imgs, nodes, edges)
# edges.iba <- igraph::as_data_frame(lgrph[[5]], what="edges")
# overlap.nodes <- unique(edges.iba[edges.iba$type == ">", "from"])
# contemp.nodes <- unique(unlist(edges.iba[edges.iba$type == "=", c("from", "to")]))
# df.stratig <- data.frame(over = rep(overlap.nodes, length(contemp.nodes)),
#                          under = contemp.nodes)
# df.stratig$pathString <- paste(lgrph[[5]]$decor,
#                                df.stratig$over,
#                                df.stratig$under,
#                                sep = "/")
# # superpo <- as.Node(df.stratig)
# # print(superpo)
# gd <- graph_from_data_frame(df.stratig, directed = TRUE, vertices = NULL)
# gd.ed <- as_data_frame(gd, what="edges")
# gd.nd <- as_data_frame(gd, what="vertices")
# rstat_nodes <- data.frame(name = gd.nd)
# rstat_edges <- data.frame(from = gd.ed$from,
#                           to = gd.ed$to)
# # rstat_nodes <- data.frame(name = c("Hadley", "David", "Romain", "Julia"))
# # rstat_edges <- data.frame(from = c(1, 1, 1, 2, 3, 3, 4, 4, 4),
# #                           to = c(2, 3, 4, 1, 1, 2, 1, 2, 3))
# gd.all <- tbl_graph(nodes = rstat_nodes, edges = rstat_edges)
# gd.all <- set.vertex.attribute(gd.all, "context", value=as.character(V(gd.all)))
imgs <- read.table(system.file("extdata", "imgs.csv", package = "iconr"),
sep=";", stringsAsFactors = FALSE)
nodes <- read.table(system.file("extdata", "nodes.csv", package = "iconr"),
sep=";", stringsAsFactors = FALSE)
edges <- read.table(system.file("extdata", "edges.csv", package = "iconr"),
sep=";", stringsAsFactors = FALSE)
lgrph <- list_dec(imgs, nodes, edges)
# edges
edges.iba <- igraph::as_data_frame(lgrph[[5]], what="edges")
over.edges <- edges.iba[edges.iba[, "type"] == ">", ]
contemp.edges <- edges.iba[edges.iba[, "type"] == "=", ]
# nodes
nodes.iba <- igraph::as_data_frame(lgrph[[5]], what="vertices")
tib.gd.nd <- as_tibble(nodes.iba) # convert nodes df to tibble
tib.gd.nd$context <- tib.gd.nd$name # the "context"
# prepare the df
tib.gd.nd$above <- tib.gd.nd$below <- tib.gd.nd$equal <- NA
class(tib.gd.nd$above) <- class(tib.gd.nd$below) <- class(tib.gd.nd$equal) <- "list" # change class
tib.gd.nd$name <- tib.gd.nd$x <- tib.gd.nd$y <- tib.gd.nd$type <- NULL
# OVER
for(n in tib.gd.nd$context){
# filter for each nodes
n.is.above <- over.edges[over.edges[, "from"] == n, ]
if (nrow(n.is.above) > 0){
tib.gd.nd[n , "below"][[1]] <- list(n.is.above[, "to"])
}
n.is.below <- over.edges[over.edges[, "to"] == n, ]
if (nrow(n.is.below) > 0){
tib.gd.nd[n , "above"][[1]] <- list(n.is.below[, "from"])
}
n.is.contemp <- contemp.edges[contemp.edges[, "from"] == n, ]
if (nrow(n.is.contemp) > 0){
tib.gd.nd[n , "equal"][[1]] <- list(n.is.contemp[, "to"])
}
}
## see equal nodes
# equals are listed in "equals" and "context"
eqs <-  tib.gd.nd[as.vector(!is.na(tib.gd.nd[, "equal"])), ]
# /!\ what if different layers ?
nds.equals <- unlist(unique(c(eqs$context, eqs$equal)))
get.eq <- get.bl <- get.ab <- list()
# df <- tib.gd.nd
for (n in nds.equals){
# n <- 2
# get
other.equal <- nds.equals[nds.equals != n]
tib.gd.nd[n, "equal"][[1]] <- list(other.equal)
}
## merge values for equal nodes
# see above for equal nodes
ab <- unique(as.vector(unlist(tib.gd.nd[nds.equals, "above"])))
ab <- ab[!is.na(ab)]
if(is.logical(ab)) ab <- NA
tib.gd.nd[nds.equals, "above"][[1]] <- list(ab)
# see below for equal nodes
bl <- unique(as.vector(unlist(tib.gd.nd[nds.equals, "below"])))
bl <- bl[!is.na(bl)]
# avoid logical(0)
if(is.logical(bl)) bl <- NA
tib.gd.nd[nds.equals, "below"][[1]] <- list(bl)
## merge for overlap nodes (non equal)
for(i in nrow(tib.gd.nd)){
# i <- 1
ov <- unique(as.vector(unlist(tib.gd.nd[i, "below"])))
node.to.add <- setdiff(nds.equals, ov)
is.above <- unique(as.vector(unlist(tib.gd.nd[node.to.add, "above"])))
}
#
all.above <- as.vector(unlist(tib.gd.nd[, "above"]))
for(i in 1:length(all.above)){
# i <- 2
# ctx <- all.above[i]
context <- as.vector(unlist(tib.gd.nd[i, "context"]))
# find the nodes where the context is above
abv <- as.character(which(all.above %in% context))
# avoid character(0)
abv[length(abv) == 0] <- NA
tib.gd.nd[i, "below"][[1]] <- list(abv)
}
# add "natural" at the bottom
tib.gd.nd[nrow(tib.gd.nd)+1, "context"] <- "natural"
# select nodes without any nodes below them
down.nodes <- as.vector(unlist(tib.gd.nd[is.na(tib.gd.nd[, "below"]), "context"]))
# the down.nodes are upper the "natural"
tib.gd.nd[nrow(tib.gd.nd), "above"][[1]] <- list(down.nodes)
# add "natural" below the down.nodes
tib.gd.nd[down.nodes, "below"][[1]] <- list("natural")
# - - - - - - - - - - - - - -
# gd.all <- tbl_graph(nodes = tib.gd.nd, edges = edges.iba)
h12_graph <- stratigraph(tib.gd.nd, "context", "above") # works harris12, ~ with 'gd.all'
# ggraph(h12_graph, layout = "sugiyama") +
#   geom_edge_elbow() +
#   geom_node_label(aes(label = context), label.r = unit(0, "mm")) +
#   theme_graph()
a.g <- ggraph(h12_graph, layout = "sugiyama") +
geom_edge_elbow() +
geom_node_label(aes(label = context), label.r = unit(0, "mm")) +
theme_graph()
# knitr::include_graphics(c("path/to/img1","path/to/img1"))
grid.arrange(ibahernando, a.g, ncol = 2)
img <- "C:/Rprojects/iconr/doc/img/Abela.jpg"
?walk
